{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://visitseattle.org/events/page/\"\n",
    "pages = 35\n",
    "events_ls = []\n",
    "for pg in range (1, pages+1):\n",
    "    url = f'{base_url}{pg}'\n",
    "    res = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    selector = \"div.search-result-preview > div > h3 > a\"\n",
    "\n",
    "    a_eles = soup.select(selector)\n",
    "\n",
    "    events_ls.append([x['href'] for x in a_eles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list\n",
    "events_ls = list(itertools.chain.from_iterable(events_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all pages have been paginated through\n",
    "len(events_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events_ls:\n",
    "    # Scrape the pages\n",
    "    response = requests.get(event).text\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    # Extract the details of the event: name, date, location, type, region\n",
    "    names = soup.find(class_=\"page-title\").text\n",
    "    date_location = soup.find('h4').text.split(\" | \")\n",
    "    type = soup.find(class_=\"button big medium black category\").text\n",
    "    region = soup.select_one('a.button.big.medium.black.category[href*=event_regions]').text\n",
    "\n",
    "    # Look up location\n",
    "    location_query = region\n",
    "\n",
    "    if '/' in location_query:\n",
    "        location_query = location_query.split(' / ')[0].strip()\n",
    "    location_query = [f'{location_query}, Seattle']\n",
    "\n",
    "    # Call API endpoint for location\n",
    "    location_url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        'q': location_query,\n",
    "        'format': 'json',\n",
    "    }\n",
    "    response = requests.get(location_url, params=params)\n",
    "    location_data = response.json()\n",
    "\n",
    "    if location_data:\n",
    "        latitude = location_data[0]['lat']\n",
    "        longitude = location_data[0]['lon']\n",
    "\n",
    "        # Use latitude and longitude to query weather API\n",
    "        weather_api_url = f\"https://api.weather.gov/points/{latitude},{longitude}\"\n",
    "        time.sleep(1)\n",
    "        weather_response = requests.get(weather_api_url)\n",
    "        weather_data = weather_response.json()\n",
    "\n",
    "        forecast_url = weather_data['properties']['forecast']\n",
    "        res = requests.get(forecast_url)\n",
    "        weather_forecast_data = res.json()\n",
    "\n",
    "        temperature = weather_forecast_data.get('properties', {}).get('periods', [{}])[0].get('temperature', '')\n",
    "        short_forecast = weather_forecast_data.get('properties', {}).get('periods', [{}])[0].get('shortForecast', '')\n",
    "\n",
    "        # Store in csv\n",
    "        with open('events.csv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "            # Write event details and weather information\n",
    "            writer.writerow([f'Event Name: {names}'])\n",
    "            writer.writerow([f'Date: {date_location[0]}'])\n",
    "            writer.writerow([f'Location: {date_location[1]}'])\n",
    "            writer.writerow([f'Type: {type}'])\n",
    "            writer.writerow([f'Region: {region}'])\n",
    "            writer.writerow([f'Temperature: {temperature}ÂºF'])\n",
    "            writer.writerow([f'Short Forecast: {short_forecast}'])\n",
    "            writer.writerow([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
